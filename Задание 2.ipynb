{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Задание 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Wall time: 1min 40s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "# распарсим \"Выстрел\" и запишем в json\n",
    "from pymystem3 import Mystem\n",
    "import json\n",
    "\n",
    "with open('Выстрел.txt') as f:\n",
    "    text = f.read()\n",
    "m = Mystem()\n",
    "with open('mystem_analysis.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(m.analyze(text), f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Wall time: 738 ms\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%%time\n",
    "# токенизируем текст с помощью nltk и анализируем с помощью pymorphy\n",
    "from nltk import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from string import punctuation\n",
    "import json\n",
    "\n",
    "with open('Выстрел.txt') as f:\n",
    "    text = f.read()\n",
    "    text = [x.strip(punctuation).lower() for x in word_tokenize(text) if x.isalpha()]\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "pymorphy_analysis = []\n",
    "for word in text:\n",
    "    word_analysis = {}\n",
    "    ana = morph.parse(word)[0]\n",
    "    word_analysis['lemma'] = ana.normal_form\n",
    "    word_analysis['part_of_speech'] = ana.tag.POS\n",
    "    pymorphy_analysis.append(word_analysis)\n",
    "\n",
    "with open('pymorphy_analysis.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(pymorphy_analysis, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Доля каждой части речи:\nNOUN 23.54%\n\nVERB 15.8%\n\nNPRO 13.56%\n\nADJF 9.9%\n\nPREP 9.81%\n\nCONJ 8.34%\n\nADVB 5.24%\n\nPRCL 4.91%\n\nINFN 2.91%\n\nADJS 1.5%\n\nGRND 1.14%\n\nPRTF 1.0%\n\nNUMR 0.89%\n\nPRTS 0.5%\n\nPRED 0.28%\n\nINTJ 0.25%\n\nCOMP 0.25%\n\nNone 0.19%\n\n\nТоп-20 глаголов:  быть, сказать, стать, знать, отвечать, продолжать, мочь, дать, иметь, сесть, ждать, встать, выйти, хотеть, увидеть, случаться, взять, видеть, бывать, вынуть\nТоп-20 наречий:  уже, никогда, однажды, очень, наконец, тут, где, почти, вечером, пешком, назад, уж, снова, несколько, чрезвычайно, обыкновенно, прежде, столь, скоро, поминутно\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# находим долю каждой из частей речи в тексте\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "with open('pymorphy_analysis.json', encoding='utf-8') as f:\n",
    "    pymorphy_analysis = json.loads(f.read())\n",
    "\n",
    "parts_of_speech = {}\n",
    "for lemma in pymorphy_analysis:\n",
    "    if lemma['part_of_speech'] not in parts_of_speech:\n",
    "        parts_of_speech[lemma['part_of_speech']] = []\n",
    "    parts_of_speech[lemma['part_of_speech']].append(lemma['lemma'])\n",
    "pos_statistics = {}\n",
    "for pos in parts_of_speech:\n",
    "    pos_statistics[pos] = len(parts_of_speech[pos])\n",
    "pos_statistics = list(pos_statistics.items())\n",
    "pos_statistics.sort(key=lambda i: i[1], reverse=True)\n",
    "print('Доля каждой части речи:')\n",
    "for pos in pos_statistics:\n",
    "    print(pos[0], round(pos[1]/len(pymorphy_analysis)*100, 2), end='')\n",
    "    print('%\\n')\n",
    "\n",
    "\n",
    "# находим топ-20 глаголов и наречий\n",
    "print()\n",
    "print('Топ-20 глаголов: ', ', '.join([word[0] for word in Counter(parts_of_speech['VERB']).most_common(20)]))\n",
    "print('Топ-20 наречий: ', ', '.join([word[0] for word in Counter(parts_of_speech['ADVB']).most_common(20)]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Топ-25 биграмм:\nя не\nя в\nваш сиятельство\nон быть\nс он\nне быть\nв наш\nи в\nс я\nя быть\nя с\nсказать он\nне знать\nу он\nон я\nчто я\nбыть в\nнаш полка\nникогда не\nмежду мы\nон не\nи не\nон в\nу я\nне иметь\n\nТоп-25 триграмм:\nв наш полка\nу я в\nпо крайний мера\nваш сиятельство не\nникто не знать\nвыйти в отставка\nв отставка и\nпоселиться в бедный\nдва или три\nон драться отвечать\nсильвио взять мел\nвзять мел и\nмы послать к\nна он глядеть\nс тот пора\nя с он\nобыкновенно тут же\nчто я не\nбыть в мой\nв мой рука\nгод тот назад\nтот назад я\nи дать я\nмолодая и прекрасный\nстать ходить взад\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "'\\nПоявление в списке сочетаний с отрицанием (\"я не\", \"не быть\"), личными местоимениями 1-го и 3-го лица (\"я быть\", \"он не\"), предлогами (\"я в\", \"у он\"),а также всевозможных их комбинаций объяснимо: все эти лексемы находятся вверху списка частотных лексем для русского языка в целом.\\nПоявление сочетаний \"наш полка\", \"в наш полка\" объясняются тематикой повести \"Выстрел\". Сочетания \"ваш сиятельство\", \"ваш сиятельство не\", \"сильвио взять мел\" отражают важных персонажей повести.\\n\"по крайний мера\" (\"по крайней мере\"), \"год тот назад\" (\"год тому назад\") -- частотные сочетания сами по себе.\\n'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 22
    }
   ],
   "source": [
    "# составим топ-25 биграмм и триграмм\n",
    "import json\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "with open('pymorphy_analysis.json', encoding='utf-8') as f:\n",
    "    text = json.loads(f.read())\n",
    "\n",
    "text = [word['lemma'] for word in text]\n",
    "bigrams = nltk.bigrams(text)\n",
    "trigrams = nltk.trigrams(text)\n",
    "print('Топ-25 биграмм:')\n",
    "print(*[' '.join(bigram[0]) for bigram in Counter(bigrams).most_common(25)], sep='\\n')\n",
    "print()\n",
    "print('Топ-25 триграмм:')\n",
    "print(*[' '.join(trigram[0]) for trigram in Counter(trigrams).most_common(25)], sep='\\n')\n",
    "\n",
    "'''\n",
    "Появление в списке сочетаний с отрицанием (\"я не\", \"не быть\"), личными местоимениями 1-го и 3-го лица (\"я быть\", \"он не\"), предлогами (\"я в\", \"у он\"),а также всевозможных их комбинаций объяснимо: все эти лексемы находятся вверху списка частотных лексем для русского языка в целом.\n",
    "Появление сочетаний \"наш полка\", \"в наш полка\" объясняются тематикой повести \"Выстрел\". Сочетания \"ваш сиятельство\", \"ваш сиятельство не\", \"сильвио взять мел\" отражают важных персонажей повести.\n",
    "\"по крайний мера\" (\"по крайней мере\"), \"год тот назад\" (\"год тому назад\") -- частотные сочетания сами по себе.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}